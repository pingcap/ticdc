#!/bin/bash

# Random DDL+DML weekly smoke test (3 captures, random failover).
#
# Timeline (high level):
#   1) start_tidb_cluster: start upstream + downstream TiDB.
#   2) random_ddl_test_runner bootstrap: create identical schemas and deterministic seed data on both sides.
#   3) start TiCDC (3 captures) and create changefeed.
#   4) random_ddl_test_runner workload:
#      - concurrent random DML + random DDL on upstream
#      - random capture kill + restart (runner failover loop)
#   5) Final diff: sync_diff_inspector compares upstream vs downstream using diff_config.toml generated by the runner.
#   6) Post-check: scan logs for panic/fatal/data race patterns.
#
# Sequence diagram (simplified):
#   run.sh
#     |-> start_tidb_cluster
#     |-> random_ddl_test_runner --phase bootstrap
#     |-> run_cdc_server (capture=3)
#     |-> cdc_cli_changefeed create
#     |-> consumer (kafka/storage/pulsar) [optional]
#     |-> random_ddl_test_runner --phase workload (includes failover)
#     |-> check_sync_diff (sync_diff_inspector)

set -eu

CUR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
source $CUR/../_utils/test_prepare

WORK_DIR=$OUT_DIR/$TEST_NAME
CDC_BINARY=cdc.test
SINK_TYPE=$1
CHANGEFEED_ID="weeklyrand"

RUN_SEED=${RUN_SEED:-1}
RUN_PROFILE=${RUN_PROFILE:-smoke}
RUN_DURATION=${RUN_DURATION:-3m}

function build_runner() {
	mkdir -p "$WORK_DIR"
	go build -o "$WORK_DIR/random_ddl_test_runner" "$CUR/../../utils/random_ddl_test_runner"
}

function write_runner_config() {
	local mysql_sync_enabled="false"
	if [ "$SINK_TYPE" == "mysql" ]; then
		mysql_sync_enabled="true"
	fi

	cat >"$WORK_DIR/runner_config.json" <<EOF
{
  "workdir": "$WORK_DIR",
  "profile": "$RUN_PROFILE",
  "seed": $RUN_SEED,
  "duration": "$RUN_DURATION",
  "upstream": { "host": "$UP_TIDB_HOST", "port": $UP_TIDB_PORT, "user": "root", "password": "" },
  "downstream": { "host": "$DOWN_TIDB_HOST", "port": $DOWN_TIDB_PORT, "user": "root", "password": "" },
  "cdc": {
    "addr": "127.0.0.1:8300",
    "user": "ticdc",
    "password": "ticdc_secret",
    "keyspace": "$KEYSPACE_NAME",
    "changefeed_id": "$CHANGEFEED_ID"
  },
  "sink_type": "$SINK_TYPE",
  "failover": {
    "enabled": true,
    "cdc_binary": "$CDC_BINARY",
    "capture_addrs": ["127.0.0.1:8300", "127.0.0.1:8301", "127.0.0.1:8302"],
    "min_interval": "20s",
    "max_interval": "40s",
    "gated_probability": 0.5
  },
  "verify": {
    "health_interval": "10s",
    "no_advance_soft": "2m",
    "no_advance_hard": "5m",
    "converge_wait": "20s",
    "panic_patterns": ["panic", "fatal", "DATA RACE"],
    "log_scan_enabled": true,
    "fail_on_panic_match": true
  },
  "mysql": {
    "enabled": $mysql_sync_enabled,
    "diff_interval": "60s",
    "max_diff_checks": 1,
    "upstream_status_host": "$UP_TIDB_HOST",
    "upstream_status_port": $UP_TIDB_STATUS
  },
  "bootstrap": {
    "db_count": 5,
    "tables_per_db": 20,
    "base_rows_per_table": 100,
    "split_rows_per_table": 500,
    "frozen_rows_per_table": 50
  }
}
EOF
}

function prepare_sink() {
	local topic="ticdc-weekly-rand-multi-failover-$RANDOM"
	case $SINK_TYPE in
	kafka)
		SINK_URI="kafka://127.0.0.1:9092/$topic?protocol=canal-json&enable-tidb-extension=true&partition-num=4&kafka-version=${KAFKA_VERSION}&max-message-bytes=10485760"
		;;
	storage)
		# Pre-create directories for local file storage sink to avoid path creation races in multi-capture mode.
		local root="$WORK_DIR/storage_test/$topic"
		mkdir -p "$root"
		for db in db1 db2 db3 db4 db5; do
			for i in $(seq -w 0 19); do
				mkdir -p "$root/$db/t${i}/meta"
				mkdir -p "$root/$db/t${i}/$start_ts"
			done
		done
		SINK_URI="file://$root?flush-interval=5s&protocol=csv"
		;;
	pulsar)
		run_pulsar_cluster $WORK_DIR normal
		SINK_URI="pulsar://127.0.0.1:6650/$topic?protocol=canal-json&enable-tidb-extension=true"
		;;
	*)
		SINK_URI="mysql://root@127.0.0.1:3306/"
		;;
	esac
}

function start_consumer_if_needed() {
	case $SINK_TYPE in
	kafka) run_kafka_consumer $WORK_DIR "$SINK_URI" "$CUR/conf/consumer.toml" "" "" ;;
	storage) run_storage_consumer $WORK_DIR "$SINK_URI" "$CUR/conf/consumer.toml" "" ;;
	pulsar) run_pulsar_consumer --upstream-uri "$SINK_URI" --config "$CUR/conf/consumer.toml" ;;
	esac
}

function cleanup() {
	set +e
	cleanup_process $CDC_BINARY >/dev/null 2>&1 || true
	cleanup_process cdc_kafka_consumer >/dev/null 2>&1 || true
	cleanup_process cdc_storage_consumer >/dev/null 2>&1 || true
	cleanup_process cdc_pulsar_consumer >/dev/null 2>&1 || true
	stop_test $WORK_DIR
}

trap 'cleanup' EXIT

rm -rf $WORK_DIR && mkdir -p $WORK_DIR

start_tidb_cluster --workdir $WORK_DIR

build_runner
write_runner_config

"$WORK_DIR/random_ddl_test_runner" --config "$WORK_DIR/runner_config.json" --phase bootstrap

if [ "$SINK_TYPE" == "mysql" ]; then
	run_sql "SET GLOBAL tidb_enable_external_ts_read = on;" ${DOWN_TIDB_HOST} ${DOWN_TIDB_PORT}
fi

start_ts=$(run_cdc_cli_tso_query ${UP_PD_HOST_1} ${UP_PD_PORT_1})

run_cdc_server --workdir $WORK_DIR --binary $CDC_BINARY --logsuffix "0" --addr "127.0.0.1:8300"
run_cdc_server --workdir $WORK_DIR --binary $CDC_BINARY --logsuffix "1" --addr "127.0.0.1:8301"
run_cdc_server --workdir $WORK_DIR --binary $CDC_BINARY --logsuffix "2" --addr "127.0.0.1:8302"

prepare_sink
if [ "$SINK_TYPE" == "mysql" ]; then
	cdc_cli_changefeed create --start-ts=$start_ts --sink-uri="$SINK_URI" -c "$CHANGEFEED_ID" --config="$CUR/conf/changefeed_mysql.toml"
else
	cdc_cli_changefeed create --start-ts=$start_ts --sink-uri="$SINK_URI" -c "$CHANGEFEED_ID" --config="$CUR/conf/changefeed.toml"
fi
start_consumer_if_needed

"$WORK_DIR/random_ddl_test_runner" --config "$WORK_DIR/runner_config.json" --phase workload

DIFF_CHECK_TIME=${DIFF_CHECK_TIME:-300}
check_sync_diff $WORK_DIR "$WORK_DIR/diff_config.toml" $DIFF_CHECK_TIME

# Scan logs after diff to catch late panics while consumers are still draining.
if command -v rg >/dev/null 2>&1; then
	if rg -n -i "panic|fatal|data race" "$WORK_DIR"/runner.log "$WORK_DIR"/ddl_trace.log "$WORK_DIR"/stdout*.log "$WORK_DIR"/cdc*.log "$WORK_DIR"/cdc_*_consumer*.log "$WORK_DIR"/cdc_*_consumer_stdout*.log 2>/dev/null | head -n 20 | rg -n . >/dev/null 2>&1; then
		echo "log scan: panic/fatal/race detected"
		rg -n -i "panic|fatal|data race" "$WORK_DIR"/runner.log "$WORK_DIR"/ddl_trace.log "$WORK_DIR"/stdout*.log "$WORK_DIR"/cdc*.log "$WORK_DIR"/cdc_*_consumer*.log "$WORK_DIR"/cdc_*_consumer_stdout*.log 2>/dev/null | head -n 50 || true
		exit 1
	fi
fi

if [ "$SINK_TYPE" == "mysql" ]; then
	run_sql "SET GLOBAL tidb_enable_external_ts_read = off;" ${DOWN_TIDB_HOST} ${DOWN_TIDB_PORT}
fi

echo "[$(date)] <<<<<< run test case $TEST_NAME success! >>>>>>"
